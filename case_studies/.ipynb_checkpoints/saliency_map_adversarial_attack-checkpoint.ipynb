{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "y_train = to_categorical(y_train, num_classes = n_classes)\n",
    "y_test = to_categorical(y_test, num_classes = n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples.tutorials'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e64b8794d4c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmnist_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"
     ]
    }
   ],
   "source": [
    "def model(x, logits=False, training=False):\n",
    "    with tf.variable_scope('conv0'):\n",
    "        z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n",
    "                             padding='same', activation=tf.nn.relu)\n",
    "        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.variable_scope('conv1'):\n",
    "        z = tf.layers.conv2d(z, filters=64, kernel_size=[3, 3],\n",
    "                             padding='same', activation=tf.nn.relu)\n",
    "        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    with tf.variable_scope('flatten'):\n",
    "        shape = z.get_shape().as_list()\n",
    "        z = tf.reshape(z, [-1, np.prod(shape[1:])])\n",
    "\n",
    "    with tf.variable_scope('mlp'):\n",
    "        z = tf.layers.dense(z, units=128, activation=tf.nn.relu)\n",
    "        z = tf.layers.dropout(z, rate=0.25, training=training)\n",
    "\n",
    "    logits_ = tf.layers.dense(z, units=10, name='logits')\n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "\n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    return y\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "def jsma(model, x, y=None, epochs=1, eps=1.0, k=1, clip_min=0.0, clip_max=1.0, score_fn=lambda t, o: t * tf.abs(o)):\n",
    "\n",
    "    n = tf.shape(x)[0] # how many images are input? n = 128 by batch size \n",
    "\n",
    "    target = tf.cond(tf.equal(0, tf.rank(y)), # tf.rank(y) returns rank of a tensor y\n",
    "                     lambda: tf.zeros([n], dtype=tf.int32) + y,\n",
    "                     lambda: y)\n",
    "\n",
    "    target = tf.stack((tf.range(n), target), axis=1) # 2xn\n",
    "\n",
    "    \"\"\"\n",
    "    x = tf.constant([1, 4])\n",
    "    y = tf.constant([2, 5])\n",
    "    z = tf.constant([3, 6])\n",
    "    tf.stack([x, y, z], axis=1)  # [[1, 2, 3], [4, 5, 6]]\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(epochs, float):\n",
    "        tmp = tf.to_float(tf.size(x[0])) * epochs\n",
    "        epochs = tf.to_int32(tf.floor(tmp))\n",
    "\n",
    "    return _jsma_impl(model, x, target, epochs=epochs, eps=eps, clip_min=clip_min, clip_max=clip_max, score_fn=score_fn)\n",
    "\n",
    "\n",
    "def _prod(iterable):\n",
    "    ret = 1\n",
    "    for x in iterable:\n",
    "        ret *= x\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _jsma_impl(model, x, yind, epochs, eps, clip_min, clip_max, score_fn):\n",
    "\n",
    "    def _cond(i, xadv):\n",
    "        return tf.less(i, epochs)\n",
    "\n",
    "    def _body(i, xadv):\n",
    "        ybar = model(xadv)\n",
    "\n",
    "        dy_dx = tf.gradients(ybar, xadv)[0] # Nx28x28x1\n",
    "\n",
    "\n",
    "        # gradients of target w.r.t input\n",
    "        yt = tf.gather_nd(ybar, yind) #yind = target = (2 x n) = random labels assigned by np.random function\n",
    "        dt_dx = tf.gradients(yt, xadv)[0]   #[0] makes it list then you can do do_dx = dy_dx - dt_dx # Nx28x28x1\n",
    "\n",
    "        # gradients of non-targets w.r.t input\n",
    "        do_dx = dy_dx - dt_dx # Nx28x28x1\n",
    "\n",
    "        c0 = tf.logical_or(eps < 0, xadv < clip_max) # returns true when either of these two is true\n",
    "        c1 = tf.logical_or(eps > 0, xadv > clip_min)\n",
    "        cond = tf.reduce_all([dt_dx >= 0, do_dx <= 0, c0, c1], axis=0)\n",
    "        cond = tf.to_float(cond) #tf.to_float([1,2,3]) produces just [1.,2.,3.] # return 0 or return 1\n",
    "\n",
    "        # saliency score for each pixel\n",
    "        score = cond * score_fn(dt_dx, do_dx) # function to calculate the saliency score for each pixel\n",
    "\n",
    "        shape = score.get_shape().as_list() # 784 x 1 matrix # To get the shape as a list of ints, do tensor.get_shape().as_list()\n",
    "        dim = _prod(shape[1:]) # multiplication except the first one\n",
    "        score = tf.reshape(score, [-1, dim]) # make 1D matrix\n",
    "\n",
    "\n",
    "        # find the pixel with the highest saliency score\n",
    "        ind = tf.argmax(score, axis=1) # find the pixel with highest value\n",
    "        dx = tf.one_hot(ind, dim, on_value=eps, off_value=0.0)\n",
    "        dx = tf.reshape(dx, [-1] + shape[1:])\n",
    "\n",
    "        xadv = tf.stop_gradient(xadv + dx)\n",
    "        xadv = tf.clip_by_value(xadv, clip_min, clip_max)\n",
    "\n",
    "        return i+1, xadv\n",
    "\n",
    "    _, xadv = tf.while_loop(_cond, _body, (0, tf.identity(x)), back_prop=False, name='_jsma_batch')\n",
    "\n",
    "    return xadv\n",
    "\n",
    "############################################################################\n",
    "\n",
    "\n",
    "class Dummy:\n",
    "    pass\n",
    "\n",
    "\n",
    "env = Dummy()\n",
    "\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    env.x = tf.placeholder(tf.float32, (None, 28, 28, 1),\n",
    "                           name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, 10), name='y')\n",
    "    env.training = tf.placeholder_with_default(False, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True, training=env.training)\n",
    "\n",
    "    with tf.variable_scope('acc'):\n",
    "        count = tf.equal(tf.argmax(env.y, axis=1), tf.argmax(env.ybar, axis=1))\n",
    "        env.acc = tf.reduce_mean(tf.cast(count, tf.float32), name='acc')\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                       logits=logits)\n",
    "        env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "    with tf.variable_scope('train_op'):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        env.train_op = optimizer.minimize(env.loss)\n",
    "\n",
    "    env.saver = tf.train.Saver()\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.target = tf.placeholder(tf.int32, (), name='target')\n",
    "    env.adv_epochs = tf.placeholder_with_default(20, shape=(), name='epochs')\n",
    "    env.adv_eps = tf.placeholder_with_default(0.2, shape=(), name='eps')\n",
    "    env.x_jsma = jsma(model, env.x, env.target, eps=env.adv_eps, epochs=env.adv_epochs)\n",
    "\n",
    "print('\\nInitializing graph')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "\n",
    "def evaluate(sess, env, X_data, y_data, batch_size=128):\n",
    "    \"\"\"\n",
    "    Evaluate TF model by running env.loss and env.acc.\n",
    "    \"\"\"\n",
    "    print('\\nEvaluating')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    loss, acc = 0, 0\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        cnt = end - start\n",
    "        batch_loss, batch_acc = sess.run(\n",
    "            [env.loss, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end]})\n",
    "        loss += batch_loss * cnt\n",
    "        acc += batch_acc * cnt\n",
    "    loss /= n_sample\n",
    "    acc /= n_sample\n",
    "\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def train(sess, env, X_data, y_data, X_valid=None, y_valid=None, epochs=1,\n",
    "          load=False, shuffle=True, batch_size=128, name='model'):\n",
    "    \"\"\"\n",
    "    Train a TF model by running env.train_op.\n",
    "    \"\"\"\n",
    "    if load:\n",
    "        if not hasattr(env, 'saver'):\n",
    "            return print('\\nError: cannot find saver op')\n",
    "        print('\\nLoading saved model')\n",
    "        return env.saver.restore(sess, 'model/{}'.format(name))\n",
    "\n",
    "    print('\\nTrain model')\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {0}/{1}'.format(epoch + 1, epochs))\n",
    "\n",
    "        if shuffle:\n",
    "            print('\\nShuffling data')\n",
    "            ind = np.arange(n_sample)\n",
    "            np.random.shuffle(ind)\n",
    "            X_data = X_data[ind]\n",
    "            y_data = y_data[ind]\n",
    "\n",
    "        for batch in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "            start = batch * batch_size\n",
    "            end = min(n_sample, start + batch_size)\n",
    "            sess.run(env.train_op, feed_dict={env.x: X_data[start:end],\n",
    "                                              env.y: y_data[start:end],\n",
    "                                              env.training: True})\n",
    "        if X_valid is not None:\n",
    "            evaluate(sess, env, X_valid, y_valid)\n",
    "\n",
    "    if hasattr(env, 'saver'):\n",
    "        print('\\n Saving model')\n",
    "        os.makedirs('model', exist_ok=True)\n",
    "        env.saver.save(sess, 'model/{}'.format(name))\n",
    "\n",
    "\n",
    "\n",
    "def make_jsma(sess, env, X_data, epochs=0.2, eps=1.0, batch_size=128):\n",
    "    \"\"\"\n",
    "    Generate JSMA by running env.x_jsma.\n",
    "    \"\"\"\n",
    "    print('\\nMaking adversarials via JSMA')\n",
    "\n",
    "    n_sample = X_data.shape[0]\n",
    "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
    "    X_adv = np.empty_like(X_data)\n",
    "\n",
    "    for batch in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
    "        start = batch * batch_size\n",
    "        end = min(n_sample, start + batch_size)\n",
    "        feed_dict = {\n",
    "            env.x: X_data[start:end],\n",
    "            env.target: np.random.choice(n_classes),\n",
    "            env.adv_epochs: epochs,\n",
    "            env.adv_eps: eps}\n",
    "        adv = sess.run(env.x_jsma, feed_dict=feed_dict)\n",
    "        X_adv[start:end] = adv\n",
    "    print()\n",
    "\n",
    "    return X_adv\n",
    "\n",
    "\n",
    "print('\\nTraining')\n",
    "\n",
    "train(sess, env, X_train, y_train, X_valid, y_valid, epochs=2)\n",
    "\n",
    "print('\\nEvaluating on clean data')\n",
    "\n",
    "evaluate(sess, env, X_test, y_test)\n",
    "\n",
    "print('\\nGenerating adversarial data')\n",
    "\n",
    "X_adv = make_jsma(sess, env, X_test, epochs=40, eps=0.8)\n",
    "\n",
    "print('\\nEvaluating on adversarial data')\n",
    "\n",
    "evaluate(sess, env, X_adv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN_env",
   "language": "python",
   "name": "nn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
